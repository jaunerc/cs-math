{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math 5 - Linear Algebra: Systems of linear equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Systems of linear equations\n",
    "We have already covered Gaussian Elimination and it's application to find the inverse of a matrix. Another application is **solving systems of linear equations**. Let's suppose we have the following system of two linear equations.\n",
    "\n",
    "$$\n",
    "x_1 - 2x_2 = 1 \\\\\n",
    "3x_1 + 2x_2 = 11\n",
    "$$\n",
    "\n",
    "The system can be written in matrix form $Ax = b$. Where $A$ is the coefficient matrix, $x$ is the vector with the unknowns and $b$ is the right hand side vector.\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}1 & -2 \\\\ 3 & 2\\end{bmatrix}\\begin{bmatrix}x_1 \\\\ x_2\\end{bmatrix} = \\begin{bmatrix}1 \\\\ 11\\end{bmatrix} \n",
    "$$\n",
    "\n",
    "The right hand side can then be added to the matrix as a new column. When we perform a row reduction for the matrix this affects also the vector $b$ (the same idea as for the inverse calculation).\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}1 & -2  & 1 \\\\ 3 & 2 & 11\\end{bmatrix} \\rightarrow \\begin{bmatrix}1 & -2  & 1 \\\\ 0 & 8 & 8\\end{bmatrix}\n",
    "\\rightarrow \\begin{bmatrix}1 & -2 & 1 \\\\ 0 & 1 & 1\\end{bmatrix}\n",
    "\\rightarrow \\begin{bmatrix}1 & 0 & 3 \\\\ 0 & 1 & 1\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "We are able to solve the system with the reduced augmented matrix in a **backsubstitution** step. In this example we can read the solution directly from the matrix.\n",
    "\n",
    "$$\n",
    "x_2 = 1, x_1 = 3\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1, -2,  1],\n",
       "       [ 3,  2, 11]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented = np.array([[1, -2, 1], [3, 2, 11]])\n",
    "augmented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The already known function `rref`is used again ;-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rref(Mat):\n",
    "    # Calculates the row-reduced-echelon-form for the given matrix\n",
    "    # from https://rosettacode.org/wiki/Reduced_row_echelon_form\n",
    "    M = np.copy(Mat)\n",
    "    lead = 0\n",
    "    row_count = len(M)\n",
    "    col_count = len(M[0])\n",
    "    for r in range(row_count):\n",
    "        if col_count <= lead:\n",
    "            return M\n",
    "        i = r\n",
    "        while M[i][lead] == 0:\n",
    "            i += 1\n",
    "            if row_count == i:\n",
    "                i = r\n",
    "                lead += 1\n",
    "                if col_count == lead:\n",
    "                    return M\n",
    "        M[i], M[r] = M[r], M[i]\n",
    "        if not M[r][lead] == 0:\n",
    "            M[r] = M[r] / M[r][lead]\n",
    "        for i in range(row_count):\n",
    "            if not i == r:\n",
    "                lv = M[i][lead]\n",
    "                M[i] = [iv - lv*rv for rv,iv in zip(M[r], M[i])]\n",
    "        lead += 1\n",
    "    return M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find the same solution as above with the `rref` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 3],\n",
       "       [0, 1, 1]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rref(augmented)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LU decomposition\n",
    "The Gaussian Elimination let us solve a system of linear equations for a single vector $b$. But, we have to repeat the whole process for any different right hand side. This is not very efficient. Therefore, we would like to avoid repeating all elimination steps over and over again. This can be done with the **LU decomposition**. Thus a matrix is written as a product of a lower- and a upper-triangular matrix.\n",
    "\n",
    "_Note: A triangular matrix is a special case for square matrices._\n",
    "$$\n",
    "L_2 = \\begin{bmatrix}a_{11} & 0 \\\\ a_{21} & a_{22}\\end{bmatrix}, \n",
    "U_2 = \\begin{bmatrix}a_{11} & a_{12} \\\\ 0 & a_{22}\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Finding these two matrices is done with a series of elimination steps. These steps are then recorded in the two matrices.\n",
    "\n",
    "$$\n",
    "Ax = b = (LU)x\n",
    "$$\n",
    "\n",
    "Usually in math programs the LU decomposition is implemented with pivoting. Then we have a third matrix $P$.\n",
    "\n",
    "$$\n",
    "PA = LU\n",
    "$$\n",
    "\n",
    "This is also the case in the `lu` function of the `scipy.linalg` module which we are using in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1, -2],\n",
       "       [ 3,  2]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[1, -2], [3, 2]])\n",
    "P, L, U = scipy.linalg.lu(A)\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we multiply these three matrices we got the matrix `A` again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1., -2.],\n",
       "       [ 3.,  2.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P.dot(L.dot(U))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Solve equations with LU decomposition\n",
    "To solve a system of linear equations with the LU decomposition we first multiply both sides with the pivot matrix.\n",
    "\n",
    "$$\n",
    "PAx = Pb = c \\equiv LUx\n",
    "$$\n",
    "\n",
    "In one forward substitution step we get $y$. We define $Ux = y$.\n",
    "\n",
    "$$\n",
    "Ly = c\n",
    "$$\n",
    "\n",
    "With $y$ we are able to find $x$ in one back substitution step.\n",
    "\n",
    "$$\n",
    "Ux = y\n",
    "$$\n",
    "\n",
    "Very nice! Let's do an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.rand(4,4)\n",
    "b = np.random.rand(4,1)\n",
    "P, L, U = scipy.linalg.lu(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we calculate $x$ and $y$. We use the function `np.linalg.solve`. This function does not compute the inverse. Instead it uses an optimized routine with **forward** and **backward substitution**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = P.dot(b)\n",
    "y = np.linalg.solve(L, d)\n",
    "x = np.linalg.solve(U, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we verify the result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(A.dot(x), b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course we can use the `solve` function directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.linalg.solve(A, b)\n",
    "np.allclose(A.dot(x), b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solve with inverse matrices\n",
    "Instead we can do the calculation with the inverse of $L$ and $U$. Thats simple for these small matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.linalg.inv(L).dot(d)\n",
    "x = np.linalg.inv(U).dot(y)\n",
    "\n",
    "np.allclose(A.dot(x), b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Different right hand side\n",
    "For a **different** right hand side we just repeat the steps for the new result vector. The LU decomposition can be **reused**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.random.rand(4,1)\n",
    "d = P.dot(b)\n",
    "y = np.linalg.solve(L, d)\n",
    "x = np.linalg.solve(U, y)\n",
    "np.allclose(A.dot(x), b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Conclusion\n",
    "Solving systems of linear equations is a standard task in linear algebra. Two variants are described in this chapter. The LU-Decomposition has the advantage that the elimination steps do not have to be repeated for a different right hand side. Calculating the inverse matrices can als be avoided. Then we have a pretty fast solver also for bigger systems. Remember that finding the inverse of a matrix has a complexity of $O(n^3)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
