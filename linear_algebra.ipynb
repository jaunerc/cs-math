{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Algebra\n",
    "This notebook contains some basic stuff for linear algebra. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Matrix Computations\n",
    "We already covered vector computations in the previous notebook. This time we work with matrices. It is possible to add, subtract or multiply matrices as long as the shape matches. For addition and subtraction is an equal shape necessary. The two matrices $A$ and $B$ have both the shape `(5, 4)`. Therefore each $ij$-element in $A$ is added or subtracted with the same $ij$-element in $B$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1.],\n",
       "       [2., 2., 2., 2.],\n",
       "       [3., 3., 3., 3.],\n",
       "       [4., 4., 4., 4.],\n",
       "       [5., 5., 5., 5.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.linspace([1, 1, 1, 1], 5, num=5)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1.,  1.],\n",
       "       [ 7.,  7.,  7.,  7.],\n",
       "       [13., 13., 13., 13.],\n",
       "       [19., 19., 19., 19.],\n",
       "       [25., 25., 25., 25.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = np.linspace([1, 1, 1, 1], 25, num=5)\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.,  2.,  2.,  2.],\n",
       "       [ 9.,  9.,  9.,  9.],\n",
       "       [16., 16., 16., 16.],\n",
       "       [23., 23., 23., 23.],\n",
       "       [30., 30., 30., 30.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A + B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   0.,   0.],\n",
       "       [ -5.,  -5.,  -5.,  -5.],\n",
       "       [-10., -10., -10., -10.],\n",
       "       [-15., -15., -15., -15.],\n",
       "       [-20., -20., -20., -20.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A - B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiplying two matrices $A$ and $B$ is only possible, if the following holds.\n",
    "* $A$ is of shape `(n, p)`\n",
    "* $B$ is of shape `(p, m)`\n",
    "\n",
    "The result is a matrix with the shape `(n, m)`. The picture below illustrates this operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![matrix multiplication scheme](images/matrix_multiplication_scheme.png)\n",
    "\n",
    "image:\n",
    "* ref: https://commons.wikimedia.org/wiki/File:Matrix_multiplication_diagram_2.svg\n",
    "* license: [Creative Commons Attribution-Share Alike 3.0 Unported](https://creativecommons.org/licenses/by-sa/3.0/deed.en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That means we cannot multiply the matrices from above. But if we use the `*` operator from python we get a result. This is the same behavior as in the examples with the vectors. The standard arithmetic operations work element-wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,   1.,   1.,   1.],\n",
       "       [ 14.,  14.,  14.,  14.],\n",
       "       [ 39.,  39.,  39.,  39.],\n",
       "       [ 76.,  76.,  76.,  76.],\n",
       "       [125., 125., 125., 125.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A * B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead we can use the `dot` function from numpy. This time the operation doesn't work and we get a nice error message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (5,4) and (5,4) not aligned: 4 (dim 1) != 5 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-1e3a8194ce1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: shapes (5,4) and (5,4) not aligned: 4 (dim 1) != 5 (dim 0)"
     ]
    }
   ],
   "source": [
    "A.dot(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define new matrices with the shapes `(10, 3)` for $A$ and `(3, 5)` for $B$. The product is a matrix $C$ with the shape `(10, 5)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.linspace([1, 1, 1], 5, num=10)\n",
    "B = np.linspace([1, 1, 1, 1, 1], 25, num=3)\n",
    "C = A.dot(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, a matrix can also be multiplied with a **scalar** or a **vector**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.        ,  5.        ,  5.        ],\n",
       "       [ 7.22222222,  7.22222222,  7.22222222],\n",
       "       [ 9.44444444,  9.44444444,  9.44444444],\n",
       "       [11.66666667, 11.66666667, 11.66666667],\n",
       "       [13.88888889, 13.88888889, 13.88888889],\n",
       "       [16.11111111, 16.11111111, 16.11111111],\n",
       "       [18.33333333, 18.33333333, 18.33333333],\n",
       "       [20.55555556, 20.55555556, 20.55555556],\n",
       "       [22.77777778, 22.77777778, 22.77777778],\n",
       "       [25.        , 25.        , 25.        ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5 * A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([63., 63., 63., 63., 63.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(3).dot(B) # the result is a vector again with the shape (1, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The order of the elements are important in every case. The multiplication with matrices is in general **not commutativ** $AB \\neq BA$. We distinguish between left- and right-side multiplication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Gaussian Elimination\n",
    "One great algorithm in linear algebra is Gaussian Elimination. This is a method to solve systems of linear equations, find the inverse or the rank of a matrix and so on. A very useful algorithm that is also part of many school exams ;-)\n",
    "\n",
    "**Row Echelon Form**\n",
    "\n",
    "The basic idea is to modify the rows of a matrix until the matrix is in the so called _row echelon form_. There are two conditions to satisfy\n",
    "* All nonzero rows are above the rows with only zero elements\n",
    "* The first element of every nonzero row (pivot element) has only zero elements left in the row and below in the column\n",
    "\n",
    "Let's do this for the following 3x3 matrix.\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}1 & 1 & 3 \\\\ 0 & 1 & 2 \\\\ 2 & 1 & 4\\end{bmatrix} \\rightarrow\n",
    "\\begin{bmatrix}1 & 1 & 3 \\\\ 0 & 1 & 2 \\\\ 0 & -1 & -2\\end{bmatrix} \\rightarrow\n",
    "\\begin{bmatrix}1 & 1 & 3 \\\\ 0 & 1 & 2 \\\\ 0 & 0 & 0\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Steps:\n",
    "1. Multiply `-2` times the `1st` row to the `3rd` row\n",
    "2. Add the `2nd` row to the `3rd` row\n",
    "\n",
    "Finally, we have two pivot elements (the leading nonzero elements in the rows 1 and 2)\n",
    "\n",
    "**Reduced Row Echelon Form**\n",
    "\n",
    "The row echelon form can be further reduced. Two additional conditions has to be satisfied.\n",
    "* All pivot elements are equal to 1\n",
    "* Each pivot column contains only zeros except the pivot element\n",
    "\n",
    "If we reduce the 3x3 matrix in the echelon form we have to subtract the `2nd` row from the `1st` row.\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}1 & 1 & 3 \\\\ 0 & 1 & 2 \\\\ 0 & 0 & 0\\end{bmatrix} \\rightarrow\n",
    "\\begin{bmatrix}1 & 0 & 1 \\\\ 0 & 1 & 2 \\\\ 0 & 0 & 0\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, numpy has no function to directly calculate the reduced row echelon form but the following function `rref` does. The code is mainly from https://rosettacode.org/wiki/Reduced_row_echelon_form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rref(Mat):\n",
    "    # Calculates the row-reduced-echelon-form for the given matrix\n",
    "    # from https://rosettacode.org/wiki/Reduced_row_echelon_form\n",
    "    M = np.copy(Mat)\n",
    "    lead = 0\n",
    "    row_count = len(M)\n",
    "    col_count = len(M[0])\n",
    "    for r in range(row_count):\n",
    "        if col_count <= lead:\n",
    "            return M\n",
    "        i = r\n",
    "        while M[i][lead] == 0:\n",
    "            i += 1\n",
    "            if row_count == i:\n",
    "                i = r\n",
    "                lead += 1\n",
    "                if col_count == lead:\n",
    "                    return M\n",
    "        M[i], M[r] = M[r], M[i]\n",
    "        if not M[r][lead] == 0:\n",
    "            M[r] = M[r] / M[r][lead]\n",
    "        for i in range(row_count):\n",
    "            if not i == r:\n",
    "                lv = M[i][lead]\n",
    "                M[i] = [iv - lv*rv for rv,iv in zip(M[r], M[i])]\n",
    "        lead += 1\n",
    "    return M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`A` is the same matrix as in the example above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 3],\n",
       "       [0, 1, 2],\n",
       "       [2, 1, 4]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[1, 1, 3], [0, 1, 2], [2, 1, 4]])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1],\n",
       "       [0, 1, 2],\n",
       "       [0, 0, 0]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rref(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The inverse of a matrix\n",
    "As seen before, the order is important when we multiply matrices. In addition, an inverse does not always exist. Those calculations are a bit more complicated than with just real numbers. Luckily, numpy has a function `inv` that calculates the inverse for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 3.],\n",
       "       [6., 6.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.linspace([1, 3], 6, num=2)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5       ,  0.25      ],\n",
       "       [ 0.5       , -0.08333333]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_inv = np.linalg.inv(A)\n",
    "A_inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify the inverse by just multiply the inverse matrix with the original matrix. The result should be an **identity matrix**. Such a matrix contains only ones on the main diagonal and zeros elsewhere.\n",
    "\n",
    "$$I_2 = \\begin{bmatrix}\n",
    "    1 & 0 \\\\\n",
    "    0 & 1\n",
    "    \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 0.00000000e+00],\n",
       "       [2.77555756e-17, 1.00000000e+00]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_inv.dot(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good! The main diagonal has only ones and the other components are almost zero due to the machine inaccuracy. Numpy has a function `allclose`  to compare two arrays element-wise which returns True if they are equal within a tolerance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(A_inv.dot(A), np.eye((2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the inverse by ourself\n",
    "But how do we find the inverse whitout a predefined function? For square-matrices with 2 or 3 dimensions exists easy equations to find the inverse thanks to [Cramer's rule](https://en.wikipedia.org/wiki/Cramer%27s_rule). Actually also for higher dimensions but then we have huge equations.\n",
    "\n",
    "In the 2x2 case we find the inverse as follows.\n",
    "\n",
    "$$A^{-1} = \\begin{bmatrix}a & b \\\\ c & d \\end{bmatrix}^{-1} = \\frac{1}{det(A)} \\begin{bmatrix}d & -b \\\\ -c & a \\end{bmatrix}$$\n",
    "\n",
    "To calculate this we need the determinant of the matrix. For 2x2 matrices this is just\n",
    "\n",
    "$$det(A) = ad - bc$$\n",
    "\n",
    "As we can see in the equation the determinant has to be nonzero. Otherwise we have a division by zero. Therefore a matrix is invertible if the determinant is not zero.\n",
    "\n",
    "_Note: The test with the determinat only works if the matrix elements are within a field. This is the case in every example in this notebook._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following snippet shows the calculation to find the inverse for a 2x2 matrix. The result is the same as the result from the `inv` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5       ,  0.25      ],\n",
       "       [ 0.5       , -0.08333333]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_det = np.linalg.det(A)\n",
    "A_prepared = np.array([[A[1][1], -A[0][1]], [-A[1][0], A[0][0]]])\n",
    "\n",
    "A_prepared.dot(1 / A_det)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gaus-Jordan method**\n",
    "\n",
    "To find the inverse of a $n \\times n$ matrix we can use an adaption of the Gaussian elimination. The matrix we want to invert is extended with the identity matrix of the same shape. The resulting augmented matrix $[A|I_3]$ is then transformed to the reduced row echelon form.\n",
    "\n",
    "$$\n",
    "A = \\begin{bmatrix}1 & 2 & 7 \\\\ 5 & 8 & 3 \\\\ 1 & 9 & 3 \\end{bmatrix}, I_3 = \\begin{bmatrix}1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The augmented matrix\n",
    "\n",
    "$$\n",
    "[A|I_3] = \\begin{bmatrix}1 & 2 & 7 & 1 & 0 & 0 \\\\ 5 & 8 & 3 & 0 & 1 & 0 \\\\ 1 & 9 & 3 & 0 & 0 & 1 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "And the reduced augmented matrix\n",
    "\n",
    "$$\n",
    "[I_3|A^{-1}] = \\begin{bmatrix}1 & 0 & 0 & -0.01293 & 0.24568 & -0.21551 \\\\\n",
    "0 & 1 & 0 & -0.05172 & -0.01724 & 0.13793 \\\\\n",
    "0 & 0 & 1 & 0.15948 & -0.03017 & -0.00862 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "As you can see the reduced matrix is separated into two parts. The first three columns left are the identity matrix again and the other columns are the inverse of $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 7],\n",
       "       [5, 8, 3],\n",
       "       [1, 9, 3]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[1, 2, 7], [5, 8, 3], [1, 9, 3]])\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the augmented matrix with the original matrix `A` and the identity matrix. Numpy has a function `eye` to create a identity matrix of a specific size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 7., 1., 0., 0.],\n",
       "       [5., 8., 3., 0., 1., 0.],\n",
       "       [1., 9., 3., 0., 0., 1.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_A = len(A[0])\n",
    "augmented = np.concatenate((A, np.eye(dim_A)), axis=1)\n",
    "augmented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce the augmented matrix with the `rref` function from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.        ,  0.        , -0.01293103,  0.24568966,\n",
       "        -0.21551724],\n",
       "       [ 0.        ,  1.        ,  0.        , -0.05172414, -0.01724138,\n",
       "         0.13793103],\n",
       "       [-0.        , -0.        ,  1.        ,  0.15948276, -0.03017241,\n",
       "        -0.00862069]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rref_augmented = rref(augmented)\n",
    "rref_augmented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inverse of `A` is in the right part of the reduced matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01293103,  0.24568966, -0.21551724],\n",
       "       [-0.05172414, -0.01724138,  0.13793103],\n",
       "       [ 0.15948276, -0.03017241, -0.00862069]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_inv = rref_augmented[:,3:6]\n",
    "A_inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We can verify this with the `inv` function from numpy and it looks good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.78676518e-16,  0.00000000e+00,  0.00000000e+00],\n",
       "       [-2.15105711e-16,  2.08166817e-17,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  3.46944695e-18, -1.73472348e-18]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_inv - np.linalg.inv(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2, 3],\n",
       "       [2, 1, 6],\n",
       "       [1, 1, 3]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[2, 2, 3], [2, 1, 6], [1, 1, 3]])\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Solve systems of linear equations\n",
    "We have already covered Gaussian Elimination and it's application to find the inverse of a matrix. Another application is **solving systems of linear equations**. Let's suppose we have the following system of two linear equations.\n",
    "\n",
    "$$\n",
    "x_1 - 2x_2 = 1 \\\\\n",
    "3x_1 + 2x_2 = 11\n",
    "$$\n",
    "\n",
    "The system can be written in matrix form $Ax = b$. Where $A$ is the coefficient matrix, $x$ is the vector with the unknowns and $b$ is the right hand side vector.\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}1 & -2 \\\\ 3 & 2\\end{bmatrix}\\begin{bmatrix}x_1 \\\\ x_2\\end{bmatrix} = \\begin{bmatrix}1 \\\\ 11\\end{bmatrix} \n",
    "$$\n",
    "\n",
    "The right hand side can then be added to the matrix as a new column. When we perform a row reduction for the matrix this affects also the vector $b$ (the same idea as for the inverse calculation).\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}1 & -2  & 1 \\\\ 3 & 2 & 11\\end{bmatrix} \\rightarrow \\begin{bmatrix}1 & -2  & 1 \\\\ 0 & 8 & 8\\end{bmatrix}\n",
    "\\rightarrow \\begin{bmatrix}1 & -2 & 1 \\\\ 0 & 1 & 1\\end{bmatrix}\n",
    "\\rightarrow \\begin{bmatrix}1 & 0 & 3 \\\\ 0 & 1 & 1\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "We are able to solve the system with the reduced augmented matrix in a **backsubstitution** step. In this example we can read the solution directly from the matrix.\n",
    "\n",
    "$$\n",
    "x_2 = 1, x_1 = 3\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1, -2,  1],\n",
       "       [ 3,  2, 11]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented = np.array([[1, -2, 1], [3, 2, 11]])\n",
    "augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 3],\n",
       "       [0, 1, 1]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rref(augmented)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. LU decomposition\n",
    "The Gaussian Elimination let us solve a system of linear equations for a single vector $b$. But, we have to repeat the whole process for any different right hand side. This is not very efficient. Therefore, we would like to avoid repeating all elimination steps over and over again. This can be done with the **LU decomposition**. Thus a matrix is written as a product of a lower- and a upper-triangular matrix.\n",
    "\n",
    "_Note: A triangular matrix is a special case for square matrices._\n",
    "$$\n",
    "L_2 = \\begin{bmatrix}a_{11} & 0 \\\\ a_{21} & a_{22}\\end{bmatrix}, \n",
    "U_2 = \\begin{bmatrix}a_{11} & a_{12} \\\\ 0 & a_{22}\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Finding these two matrices is done with a series of elimination steps. These steps are then recorded in the two matrices.\n",
    "\n",
    "$$\n",
    "Ax = b = (LU)x\n",
    "$$\n",
    "\n",
    "Usually in math programs the LU decomposition is implemented with pivoting. Then we have a third matrix $P$.\n",
    "\n",
    "$$\n",
    "PA = LU\n",
    "$$\n",
    "\n",
    "This is also the case in the `lu` function of the `scipy.linalg` module which we are using in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1, -2],\n",
       "       [ 3,  2]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[1, -2], [3, 2]])\n",
    "P, L, U = scipy.linalg.lu(A)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        ],\n",
       "       [0.33333333, 1.        ]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.        ,  2.        ],\n",
       "       [ 0.        , -2.66666667]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we multiply those three matrices together we got the matrix `A`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1., -2.],\n",
       "       [ 3.,  2.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P.dot(L.dot(U))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve equations with LU decomposition\n",
    "To solve a system of linear equations with the LU decomposition we first multiply both sides with the pivot matrix.\n",
    "\n",
    "$$\n",
    "PAx = Pb = c \\equiv LUx\n",
    "$$\n",
    "\n",
    "In one forward substitution step we get $y$. We define $Ux = y$.\n",
    "\n",
    "$$\n",
    "Ly = c\n",
    "$$\n",
    "\n",
    "With $y$ we are able to find $x$ in one back substitution step.\n",
    "\n",
    "$$\n",
    "Ux = y\n",
    "$$\n",
    "\n",
    "Very nice! Let's do an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.rand(4,4)\n",
    "b = np.random.rand(4,1)\n",
    "P, L, U = scipy.linalg.lu(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we calculate $x$ and $y$. We use the function `np.linalg.solve`. This function does not compute the inverse. Instead it uses an optimized routine with forward and backward substitution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = P.dot(b)\n",
    "y = np.linalg.solve(L, d)\n",
    "x = np.linalg.solve(U, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then verify the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(A.dot(x), b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course we can use the `solve` function directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.linalg.solve(A, b)\n",
    "np.allclose(A.dot(x), b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead we can do the calculation with the inverse of $L$ and $U$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.linalg.inv(L).dot(d)\n",
    "x = np.linalg.inv(U).dot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(A.dot(x), b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a **different** right hand side we just repeat the steps for the new result vector. The LU decomposition can be reused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.random.rand(4,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = P.dot(b)\n",
    "y = np.linalg.solve(L, d)\n",
    "x = np.linalg.solve(U, y)\n",
    "np.allclose(A.dot(x), b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Vector Space\n",
    "The next topic in this notebook is about vector space. By definition a vector space consists of a set $V$, a field $F$ and the two operations *vector addition* and *scalar multiplication*. $V$ holds vector elements and $F$ holds scalars. We only consider *real* vector spaces here. That means the field is always $\\mathbb{R}$.\n",
    "\n",
    "For example the space $\\mathbb{R}^2$ consists all column vectors with 2 components. We need two base vectors to describe this space. These two vectors have to be **lineary independent**. Here is an example\n",
    "\n",
    "$$\n",
    "\\vec{v}_1 = \\begin{bmatrix}1 \\\\ 0\\end{bmatrix}, \\vec{v}_2 = \\begin{bmatrix}0 \\\\ 1\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "But there are different vectors possible as long as they are lineary independent. This is the case, if one is not a multiple of the other (2D case).\n",
    "\n",
    "More general: *Lineary independent vectors only adds up to the zero vector if each vector is multiplied with zero*.\n",
    "\n",
    "$$\\lambda_1\\vec{v}_1 + \\lambda_2\\vec{v}_2 + \\ldots + \\lambda_n\\vec{v}_n = \\vec{0} \\textrm{, where } \\lambda_1 = \\lambda_2 = \\ldots = \\lambda_n = 0$$\n",
    "\n",
    "For example, we see quite simply that the conditions do not apply to the following vectors $\\vec{a}_1$ and $\\vec{a}_2$. Any addition of the vectors results in a zero vector regardless of the values of the scalars. Therefore they are not lineary independent.\n",
    "\n",
    "$$\\vec{a}_1 = \\begin{bmatrix}1 \\\\ 1\\end{bmatrix}, \\vec{a}_2 = \\begin{bmatrix}-1 \\\\ -1\\end{bmatrix}$$\n",
    "\n",
    "**Conclusion:** The $n$ vectors span a vector space $V$. The number of basis vectors is equal to the **dimension** of the vector space.\n",
    "\n",
    "### The rank of a matrix\n",
    "The `rref` form gives us further informations about a matrix. The number of pivots is called the **rank** of a matrix. This number tells us how many dimensions the vector space spanned by its columns has. The matrix $A$ in the next section is written in its `rref` form. We have two pivots. This means that the vector space has also two dimensions.\n",
    "\n",
    "$$\n",
    "A = \\begin{bmatrix}1 & 1 & 2 & 4 \\\\ 1 & 2 & 2 & 5 \\\\ 1 & 3 & 2 & 6\\end{bmatrix} \\rightarrow\n",
    "\\textrm{rref}(A) = \\begin{bmatrix}1 & 0 & 2 & 3 \\\\ 0 & 1 & 0 & 1 \\\\ 0 & 0 & 0 & 0\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 2, 3],\n",
       "       [0, 1, 0, 1],\n",
       "       [0, 0, 0, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[1,1,2,4],[1,2,2,5],[1,3,2,6]])\n",
    "rref(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subspaces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
